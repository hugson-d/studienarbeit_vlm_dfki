Job 2377994: Running on node(s) serv-3345
Job 2377994: Started at 2025-12-10 21:18:15+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2377994&from=1765397895000
srun: jobinfo: version v1.0.0
Job 2377994: Running on node(s) serv-3345
Job 2377994: Started at 2025-12-10 21:18:16+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2377994&from=1765397896000
Job 2377994: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2377994: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 13.1 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_qwen/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
[2025-12-10 21:22:16] INFO run_qwen3_vl_30b_vllm_cot_voting.py:234: üöÄ Starte Benchmark: 3557 Aufgaben verbleibend
[2025-12-10 21:22:16] INFO run_qwen3_vl_30b_vllm_cot_voting.py:102: üèóÔ∏è Lade Qwen/Qwen3-VL-30B-A3B-Instruct mit vLLM
[2025-12-10 21:22:16] INFO run_qwen3_vl_30b_vllm_cot_voting.py:103: ‚öôÔ∏è Config: CoT + Voting (k=5, T=0.0)
[2025-12-10 21:22:16] INFO run_qwen3_vl_30b_vllm_cot_voting.py:104: üìÅ Output File: /netscratch/dhug/studienarbeit_vlm_dfki/evaluation_results/Qwen3-VL-30B-Instruct_CoT-Voting_n5_results.jsonl
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/13 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:   8% Completed | 1/13 [00:01<00:15,  1.28s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  15% Completed | 2/13 [00:05<00:31,  2.87s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  23% Completed | 3/13 [00:09<00:34,  3.41s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  31% Completed | 4/13 [00:12<00:29,  3.30s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  38% Completed | 5/13 [00:16<00:28,  3.57s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  46% Completed | 6/13 [00:20<00:26,  3.72s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  54% Completed | 7/13 [00:24<00:23,  3.84s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  62% Completed | 8/13 [00:28<00:19,  3.91s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  69% Completed | 9/13 [00:32<00:15,  3.97s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  77% Completed | 10/13 [00:36<00:12,  4.01s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  85% Completed | 11/13 [00:40<00:08,  4.02s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards:  92% Completed | 12/13 [00:44<00:04,  4.03s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards: 100% Completed | 13/13 [00:49<00:00,  4.12s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Loading safetensors checkpoint shards: 100% Completed | 13/13 [00:49<00:00,  3.79s/it]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m 
[0;36m(EngineCore_DP0 pid=2234203)[0;0m 2025-12-10 21:25:15,046 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[0;36m(EngineCore_DP0 pid=2234203)[0;0m 2025-12-10 21:25:15,079 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|‚ñè         | 1/51 [00:00<00:30,  1.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|‚ñå         | 3/51 [00:00<00:10,  4.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|‚ñâ         | 5/51 [00:00<00:06,  6.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|‚ñà‚ñé        | 7/51 [00:01<00:05,  8.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|‚ñà‚ñä        | 9/51 [00:02<00:11,  3.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|‚ñà‚ñà‚ñè       | 11/51 [00:02<00:08,  4.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|‚ñà‚ñà‚ñå       | 13/51 [00:02<00:06,  6.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:02<00:05,  7.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:02<00:04,  8.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:03<00:03,  9.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:03<00:02, 10.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:03<00:04,  6.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:04<00:03,  7.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:04<00:02,  8.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:04<00:02,  9.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:04<00:01,  9.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:04<00:01, 10.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:04<00:01, 10.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:05<00:01,  6.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:05<00:01,  7.25it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:06<00:01,  4.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:06<00:01,  4.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:07<00:01,  4.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:07<00:01,  3.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:08<00:00,  3.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:08<00:00,  3.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:09<00:00,  3.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:09<00:00,  5.51it/s]
[0;36m(EngineCore_DP0 pid=2234203)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   4%|‚ñç         | 2/51 [00:00<00:03, 14.12it/s]Capturing CUDA graphs (decode, FULL):   8%|‚ñä         | 4/51 [00:00<00:03, 14.11it/s]Capturing CUDA graphs (decode, FULL):  12%|‚ñà‚ñè        | 6/51 [00:00<00:03, 14.48it/s]Capturing CUDA graphs (decode, FULL):  16%|‚ñà‚ñå        | 8/51 [00:00<00:02, 14.66it/s]Capturing CUDA graphs (decode, FULL):  20%|‚ñà‚ñâ        | 10/51 [00:00<00:02, 14.80it/s]Capturing CUDA graphs (decode, FULL):  24%|‚ñà‚ñà‚ñé       | 12/51 [00:00<00:02, 14.81it/s]Capturing CUDA graphs (decode, FULL):  27%|‚ñà‚ñà‚ñã       | 14/51 [00:00<00:02, 14.81it/s]Capturing CUDA graphs (decode, FULL):  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:02, 14.91it/s]Capturing CUDA graphs (decode, FULL):  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:02, 14.98it/s]Capturing CUDA graphs (decode, FULL):  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:01<00:02, 14.88it/s]Capturing CUDA graphs (decode, FULL):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:01<00:01, 14.91it/s]Capturing CUDA graphs (decode, FULL):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:01<00:01, 14.92it/s]Capturing CUDA graphs (decode, FULL):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:01<00:01, 14.81it/s]Capturing CUDA graphs (decode, FULL):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:01<00:01, 14.86it/s]Capturing CUDA graphs (decode, FULL):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:02<00:01, 14.83it/s]Capturing CUDA graphs (decode, FULL):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:02<00:01, 14.74it/s]Capturing CUDA graphs (decode, FULL):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:02<00:01, 14.74it/s]Capturing CUDA graphs (decode, FULL):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:02<00:01, 14.84it/s]Capturing CUDA graphs (decode, FULL):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:02<00:00, 14.84it/s]Capturing CUDA graphs (decode, FULL):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:02<00:00, 14.91it/s]Capturing CUDA graphs (decode, FULL):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:02<00:00, 14.85it/s]Capturing CUDA graphs (decode, FULL):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:02<00:00, 14.86it/s]Capturing CUDA graphs (decode, FULL):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:03<00:00, 14.69it/s]Capturing CUDA graphs (decode, FULL):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:03<00:00, 14.81it/s]Capturing CUDA graphs (decode, FULL):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:03<00:00, 14.87it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:03<00:00, 14.81it/s]
Traceback (most recent call last):
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen3_vl_30b_vllm_cot_voting.py", line 305, in <module>
    run_benchmark()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen3_vl_30b_vllm_cot_voting.py", line 236, in run_benchmark
    evaluator = VLMEvaluator()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen3_vl_30b_vllm_cot_voting.py", line 117, in __init__
    self.sampling_params = SamplingParams(
  File "/usr/local/lib/python3.10/dist-packages/vllm/sampling_params.py", line 358, in __post_init__
    self._verify_greedy_sampling()
  File "/usr/local/lib/python3.10/dist-packages/vllm/sampling_params.py", line 451, in _verify_greedy_sampling
    raise ValueError(f"n must be 1 when using greedy sampling, got {self.n}.")
ValueError: n must be 1 when using greedy sampling, got 5.
srun: error: serv-3345: task 0: Exited with exit code 1
