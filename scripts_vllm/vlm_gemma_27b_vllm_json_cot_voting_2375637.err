Job 2375637: Running on node(s) serv-3315
Job 2375637: Started at 2025-12-10 10:36:27+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375637&from=1765359387000
srun: jobinfo: version v1.0.0
Job 2375637: Running on node(s) serv-3315
Job 2375637: Started at 2025-12-10 10:36:28+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375637&from=1765359388000
Job 2375637: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375637: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 20.5 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_qwen/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
[2025-12-10 10:40:32] INFO run_gemma_27b_vllm_cot_voting.py:242: üöÄ Starte Benchmark: 3557 Aufgaben verbleibend
[2025-12-10 10:40:32] INFO run_gemma_27b_vllm_cot_voting.py:108: üèóÔ∏è Lade google/gemma-3-27b-it mit vLLM
[2025-12-10 10:40:32] INFO run_gemma_27b_vllm_cot_voting.py:109: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=4160207)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[0;36m(EngineCore_DP0 pid=4160207)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=4160207)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 847, in run_engine_core
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self._init_executor()
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     model = initialize_model(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3_mm.py", line 533, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.language_model = init_vllm_registered_model(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 359, in init_vllm_registered_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     return initialize_model(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3.py", line 539, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.model = Gemma3Model(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3.py", line 383, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 605, in make_layers
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     + [
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 606, in <listcomp>
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3.py", line 385, in <lambda>
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     lambda prefix: Gemma3DecoderLayer(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3.py", line 322, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.mlp = Gemma3MLP(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/gemma3.py", line 73, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     self.quant_method.create_weights(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     data=torch.empty(
[0;36m(EngineCore_DP0 pid=4160207)[0;0m   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=4160207)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=4160207)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 442.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 210.50 MiB is free. Including non-PyTorch memory, this process has 39.28 GiB memory in use. Of the allocated memory 38.56 GiB is allocated by PyTorch, and 222.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_gemma_27b_vllm_cot_voting.py", line 312, in <module>
    run_benchmark()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_gemma_27b_vllm_cot_voting.py", line 244, in run_benchmark
    evaluator = VLMEvaluator()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_gemma_27b_vllm_cot_voting.py", line 115, in __init__
    self.llm = LLM(
  File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 334, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 642, in __init__
    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 471, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
  File "/usr/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
srun: error: serv-3315: task 0: Exited with exit code 1
