Job 2375646: Running on node(s) serv-3315
Job 2375646: Started at 2025-12-10 10:46:46+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375646&from=1765360006000
srun: jobinfo: version v1.0.0
Job 2375646: Running on node(s) serv-3315
Job 2375646: Started at 2025-12-10 10:46:47+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375646&from=1765360007000
Job 2375646: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375646: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 21.7 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_qwen/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
[2025-12-10 10:51:14] INFO run_ovis2_5_9b_vllm_cot_voting.py:240: üöÄ Starte Benchmark: 3557 Aufgaben verbleibend
[2025-12-10 10:51:14] INFO run_ovis2_5_9b_vllm_cot_voting.py:108: üèóÔ∏è Lade AIDC-AI/Ovis2.5-9B mit vLLM
[2025-12-10 10:51:14] INFO run_ovis2_5_9b_vllm_cot_voting.py:109: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
/usr/local/lib/python3.10/dist-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead
  warnings.warn(
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:16<00:50, 16.96s/it]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:29<00:28, 14.26s/it]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:46<00:15, 15.37s/it]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:08<00:00, 18.04s/it]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:08<00:00, 17.04s/it]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m 
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|‚ñç         | 2/51 [00:00<00:03, 12.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|‚ñä         | 4/51 [00:00<00:04, 11.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|‚ñà‚ñè        | 6/51 [00:00<00:03, 12.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|‚ñà‚ñå        | 8/51 [00:00<00:03, 13.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|‚ñà‚ñâ        | 10/51 [00:00<00:02, 14.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|‚ñà‚ñà‚ñé       | 12/51 [00:00<00:02, 15.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|‚ñà‚ñà‚ñã       | 14/51 [00:00<00:02, 15.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:02, 16.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:01, 18.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:01<00:01, 18.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:01<00:01, 18.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:01<00:01, 20.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:01<00:01, 20.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:01<00:00, 19.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:01<00:00, 20.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:02<00:00, 21.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:02<00:00, 20.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:02<00:00, 21.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:02<00:00, 22.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:02<00:00, 22.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:02<00:00, 18.89it/s]
[0;36m(EngineCore_DP0 pid=4164262)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|‚ñå         | 2/35 [00:00<00:02, 12.59it/s]Capturing CUDA graphs (decode, FULL):  14%|‚ñà‚ñç        | 5/35 [00:00<00:01, 18.19it/s]Capturing CUDA graphs (decode, FULL):  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 20.01it/s]Capturing CUDA graphs (decode, FULL):  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 19.03it/s]Capturing CUDA graphs (decode, FULL):  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:00<00:01, 20.42it/s]Capturing CUDA graphs (decode, FULL):  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:00<00:00, 21.39it/s]Capturing CUDA graphs (decode, FULL):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:00<00:00, 21.06it/s]Capturing CUDA graphs (decode, FULL):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 20.22it/s]Capturing CUDA graphs (decode, FULL):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 21.10it/s]Capturing CUDA graphs (decode, FULL):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 21.12it/s]Capturing CUDA graphs (decode, FULL):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:01<00:00, 21.49it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:01<00:00, 22.32it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:01<00:00, 20.78it/s]
Ovis2.5-9B_CoT-Voting_n1:   0%|          | 0/3557 [00:00<?, ?it/s]Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Ovis2.5-9B_CoT-Voting_n1:   0%|          | 0/3557 [00:15<?, ?it/s, acc=100.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 1/3557 [00:15<15:12:49, 15.40s/it, acc=100.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 1/3557 [00:18<15:12:49, 15.40s/it, acc=100.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 2/3557 [00:18<7:47:01,  7.88s/it, acc=100.0%, conf=1.00, last=‚úì] Ovis2.5-9B_CoT-Voting_n1:   0%|          | 2/3557 [00:21<7:47:01,  7.88s/it, acc=100.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 3/3557 [00:21<5:37:27,  5.70s/it, acc=100.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 3/3557 [00:35<5:37:27,  5.70s/it, acc=75.0%, conf=0.00, last=‚úó] Ovis2.5-9B_CoT-Voting_n1:   0%|          | 4/3557 [00:35<9:05:24,  9.21s/it, acc=75.0%, conf=0.00, last=‚úó]Ovis2.5-9B_CoT-Voting_n1:   0%|          | 4/3557 [00:39<9:05:24,  9.21s/it, acc=80.0%, conf=1.00, last=‚úì]Ovis2.5-9B_CoT-Voting_n1:   0%|          |