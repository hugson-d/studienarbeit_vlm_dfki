Job 2375647: Running on node(s) serv-3315
Job 2375647: Started at 2025-12-10 10:41:34+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375647&from=1765359694000
srun: jobinfo: version v1.0.0
Job 2375647: Running on node(s) serv-3315
Job 2375647: Started at 2025-12-10 10:41:35+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375647&from=1765359695000
Job 2375647: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375647: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 20.5 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_qwen/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
[2025-12-10 10:45:55] INFO run_qwen2_5_vl_32b_vllm_cot_voting.py:240: üöÄ Starte Benchmark: 3557 Aufgaben verbleibend
[2025-12-10 10:45:55] INFO run_qwen2_5_vl_32b_vllm_cot_voting.py:108: üèóÔ∏è Lade Qwen/Qwen2.5-VL-32B-Instruct mit vLLM
[2025-12-10 10:45:55] INFO run_qwen2_5_vl_32b_vllm_cot_voting.py:109: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
[2025-12-10 10:45:55] INFO run_qwen2_5_vl_32b_vllm_cot_voting.py:110: üìÅ Output File: /netscratch/dhug/studienarbeit_vlm_dfki/evaluation_results/Qwen2.5-VL-32B-Instruct_CoT-Voting_n1_results.jsonl
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=4162368)[0;0m The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
[0;36m(EngineCore_DP0 pid=4162368)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=4162368)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 847, in run_engine_core
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self._init_executor()
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     model = initialize_model(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2_5_vl.py", line 1222, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.language_model = init_vllm_registered_model(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 359, in init_vllm_registered_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     return initialize_model(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2.py", line 512, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.model = Qwen2Model(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2.py", line 365, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 605, in make_layers
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     + [
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/utils.py", line 606, in <listcomp>
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2.py", line 367, in <lambda>
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     lambda prefix: decoder_layer_type(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2.py", line 243, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.mlp = Qwen2MLP(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/qwen2.py", line 85, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     self.quant_method.create_weights(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     data=torch.empty(
[0;36m(EngineCore_DP0 pid=4162368)[0;0m   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=4162368)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=4162368)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 540.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 414.50 MiB is free. Including non-PyTorch memory, this process has 39.08 GiB memory in use. Of the allocated memory 38.48 GiB is allocated by PyTorch, and 106.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen2_5_vl_32b_vllm_cot_voting.py", line 311, in <module>
    run_benchmark()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen2_5_vl_32b_vllm_cot_voting.py", line 242, in run_benchmark
    evaluator = VLMEvaluator()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/vllm_models/run_qwen2_5_vl_32b_vllm_cot_voting.py", line 113, in __init__
    self.llm = LLM(
  File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 334, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 642, in __init__
    super().__init__(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/core_client.py", line 471, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
  File "/usr/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/usr/local/lib/python3.10/dist-packages/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
srun: error: serv-3315: task 0: Exited with exit code 1
