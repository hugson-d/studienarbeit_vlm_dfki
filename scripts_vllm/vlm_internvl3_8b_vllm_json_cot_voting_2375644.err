Job 2375644: Running on node(s) serv-3335
Job 2375644: Started at 2025-12-10 10:47:34+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375644&from=1765360054000
srun: jobinfo: version v1.0.0
Job 2375644: Running on node(s) serv-3335
Job 2375644: Started at 2025-12-10 10:47:38+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375644&from=1765360058000
Job 2375644: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375644: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 21.0 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_internvl/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
transformer-engine 1.1.0+cf6fc89 requires flash-attn!=2.0.9,!=2.1.0,<=2.3.3,>=1.0.6, which is not installed.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
[2025-12-10 10:52:06] INFO run_internvl3_8b_vllm_cot_voting.py:281: üöÄ Starte InternVL3-8B-CoT-Voting_n1: 3557 Aufgaben offen
[2025-12-10 10:52:06] INFO run_internvl3_8b_vllm_cot_voting.py:140: üèóÔ∏è Lade InternVL3-8B-CoT-Voting_n1 mit vLLM
[2025-12-10 10:52:06] INFO run_internvl3_8b_vllm_cot_voting.py:141: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[2025-12-10 10:52:08] INFO configuration_internvl_chat.py:69: vision_select_layer: -1
[2025-12-10 10:52:08] INFO configuration_internvl_chat.py:70: ps_version: v2
[2025-12-10 10:52:08] INFO configuration_internvl_chat.py:71: min_dynamic_patch: 1
[2025-12-10 10:52:08] INFO configuration_internvl_chat.py:72: max_dynamic_patch: 12
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:19<00:59, 19.86s/it]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:24<00:22, 11.06s/it]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:42<00:14, 14.21s/it]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:01<00:00, 16.06s/it]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:01<00:00, 15.40s/it]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m 
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|‚ñç         | 2/51 [00:00<00:02, 19.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|‚ñä         | 4/51 [00:00<00:02, 19.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|‚ñà‚ñè        | 6/51 [00:00<00:02, 18.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|‚ñà‚ñä        | 9/51 [00:00<00:02, 20.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|‚ñà‚ñà‚ñé       | 12/51 [00:00<00:01, 21.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:00<00:01, 20.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:00<00:01, 21.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:00<00:01, 23.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:01<00:01, 24.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:01<00:01, 23.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:01<00:00, 24.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:01<00:00, 25.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:01<00:00, 26.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:01<00:00, 24.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:01<00:00, 24.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:01<00:00, 27.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:02<00:00, 27.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:02<00:00, 24.22it/s]
[0;36m(EngineCore_DP0 pid=4154846)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|‚ñå         | 2/35 [00:00<00:01, 19.83it/s]Capturing CUDA graphs (decode, FULL):  14%|‚ñà‚ñç        | 5/35 [00:00<00:01, 25.51it/s]Capturing CUDA graphs (decode, FULL):  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:00, 27.04it/s]Capturing CUDA graphs (decode, FULL):  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:00, 27.48it/s]Capturing CUDA graphs (decode, FULL):  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:00<00:00, 26.66it/s]Capturing CUDA graphs (decode, FULL):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:00<00:00, 28.36it/s]Capturing CUDA graphs (decode, FULL):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:00<00:00, 30.00it/s]Capturing CUDA graphs (decode, FULL):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:00<00:00, 28.57it/s]Capturing CUDA graphs (decode, FULL):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 29.56it/s]Capturing CUDA graphs (decode, FULL):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 30.96it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:01<00:00, 29.08it/s]
