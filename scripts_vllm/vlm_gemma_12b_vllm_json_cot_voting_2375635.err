Job 2375635: Running on node(s) serv-3316
Job 2375635: Started at 2025-12-10 10:36:12+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375635&from=1765359372000
srun: jobinfo: version v1.0.0
Job 2375635: Running on node(s) serv-3316
Job 2375635: Started at 2025-12-10 10:36:13+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375635&from=1765359373000
Job 2375635: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375635: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 21.2 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_qwen/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
[2025-12-10 10:40:33] INFO run_gemma_12b_vllm_cot_voting.py:242: üöÄ Starte Benchmark: 3557 Aufgaben verbleibend
[2025-12-10 10:40:33] INFO run_gemma_12b_vllm_cot_voting.py:108: üèóÔ∏è Lade google/gemma-3-12b-it mit vLLM
[2025-12-10 10:40:33] INFO run_gemma_12b_vllm_cot_voting.py:109: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:16<01:07, 16.84s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:32<00:47, 15.99s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:47<00:31, 15.88s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [01:00<00:14, 14.44s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [01:08<00:00, 12.21s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [01:08<00:00, 13.69s/it]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m 
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|‚ñè         | 1/51 [00:00<00:06,  7.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|‚ñå         | 3/51 [00:00<00:04,  9.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|‚ñâ         | 5/51 [00:00<00:04, 10.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|‚ñà‚ñå        | 8/51 [00:00<00:04, 10.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|‚ñà‚ñâ        | 10/51 [00:00<00:03, 10.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03, 10.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03, 11.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:02, 11.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:02, 11.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:01<00:02, 12.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:01<00:02, 12.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02, 12.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:01, 12.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:01, 13.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:02<00:01, 13.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:02<00:01, 13.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:02<00:01, 13.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:02<00:01, 14.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:00, 13.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:03<00:00, 13.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:03<00:00, 14.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:03<00:00, 14.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:03<00:00, 14.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:03<00:00, 15.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:03<00:00, 15.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:03<00:00, 12.79it/s]
[0;36m(EngineCore_DP0 pid=3987696)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   3%|‚ñé         | 1/35 [00:00<00:03,  8.93it/s]Capturing CUDA graphs (decode, FULL):   9%|‚ñä         | 3/35 [00:00<00:02, 12.07it/s]Capturing CUDA graphs (decode, FULL):  14%|‚ñà‚ñç        | 5/35 [00:00<00:02, 13.13it/s]Capturing CUDA graphs (decode, FULL):  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.11it/s]Capturing CUDA graphs (decode, FULL):  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:02, 12.98it/s]Capturing CUDA graphs (decode, FULL):  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 13.74it/s]Capturing CUDA graphs (decode, FULL):  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 14.33it/s]Capturing CUDA graphs (decode, FULL):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 14.26it/s]Capturing CUDA graphs (decode, FULL):  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:01, 14.48it/s]Capturing CUDA graphs (decode, FULL):  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:01, 14.85it/s]Capturing CUDA graphs (decode, FULL):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 15.34it/s]Capturing CUDA graphs (decode, FULL):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 14.57it/s]Capturing CUDA graphs (decode, FULL):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 15.33it/s]Capturing CUDA graphs (decode, FULL):  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 16.12it/s]Capturing CUDA graphs (decode, FULL):  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 16.81it/s]Capturing CUDA graphs (decode, FULL):  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 16.59it/s]Capturing CUDA graphs (decode, FULL):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 16.83it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 17.36it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 15.11it/s]
Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 0/3557 [00:00<?, ?it/s]Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 0/3557 [00:28<?, ?it/s, acc=100.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 1/3557 [00:28<28:22:16, 28.72s/it, acc=100.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 1/3557 [00:33<28:22:16, 28.72s/it, acc=100.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 2/3557 [00:33<14:29:39, 14.68s/it, acc=100.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 2/3557 [00:58<14:29:39, 14.68s/it, acc=66.7%, conf=0.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 3/3557 [00:58<18:57:52, 19.21s/it, acc=66.7%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 3/3557 [01:01<18:57:52, 19.21s/it, acc=50.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 4/3557 [01:01<12:46:52, 12.95s/it, acc=50.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 4/3557 [01:19<12:46:52, 12.95s/it, acc=60.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 5/3557 [01:19<14:28:46, 14.68s/it, acc=60.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 5/3557 [01:43<14:28:46, 14.68s/it, acc=50.0%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 6/3557 [01:43<17:51:00, 18.10s/it, acc=50.0%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 6/3557 [02:08<17:51:00, 18.10s/it, acc=42.9%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 7/3557 [02:08<19:59:23, 20.27s/it, acc=42.9%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 7/3557 [02:12<19:59:23, 20.27s/it, acc=37.5%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 8/3557 [02:12<14:44:41, 14.96s/it, acc=37.5%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 8/3557 [02:16<14:44:41, 14.96s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 9/3557 [02:16<11:29:41, 11.66s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 9/3557 [02:20<11:29:41, 11.66s/it, acc=40.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 10/3557 [02:20<9:01:57,  9.17s/it, acc=40.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 10/3557 [02:25<9:01:57,  9.17s/it, acc=36.4%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 11/3557 [02:25<7:50:47,  7.97s/it, acc=36.4%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 11/3557 [02:38<7:50:47,  7.97s/it, acc=41.7%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 12/3557 [02:38<9:27:45,  9.61s/it, acc=41.7%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 12/3557 [02:44<9:27:45,  9.61s/it, acc=38.5%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 13/3557 [02:44<8:11:34,  8.32s/it, acc=38.5%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 13/3557 [02:46<8:11:34,  8.32s/it, acc=35.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 14/3557 [02:46<6:29:27,  6.60s/it, acc=35.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 14/3557 [02:51<6:29:27,  6.60s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 15/3557 [02:51<5:57:48,  6.06s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 15/3557 [03:01<5:57:48,  6.06s/it, acc=31.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 16/3557 [03:01<7:12:26,  7.33s/it, acc=31.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 16/3557 [03:21<7:12:26,  7.33s/it, acc=35.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 17/3557 [03:21<10:42:44, 10.89s/it, acc=35.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   0%|          | 17/3557 [03:24<10:42:44, 10.89s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 18/3557 [03:24<8:31:42,  8.68s/it, acc=33.3%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 18/3557 [03:49<8:31:42,  8.68s/it, acc=31.6%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 19/3557 [03:49<13:16:54, 13.51s/it, acc=31.6%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 19/3557 [04:08<13:16:54, 13.51s/it, acc=30.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 20/3557 [04:08<14:52:03, 15.13s/it, acc=30.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 20/3557 [04:15<14:52:03, 15.13s/it, acc=33.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 21/3557 [04:15<12:24:04, 12.63s/it, acc=33.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 21/3557 [04:39<12:24:04, 12.63s/it, acc=31.8%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 22/3557 [04:39<15:59:22, 16.28s/it, acc=31.8%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 22/3557 [05:03<15:59:22, 16.28s/it, acc=34.8%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 23/3557 [05:03<18:00:35, 18.35s/it, acc=34.8%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 23/3557 [05:10<18:00:35, 18.35s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 24/3557 [05:10<14:50:46, 15.13s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 24/3557 [05:14<14:50:46, 15.13s/it, acc=32.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 25/3557 [05:14<11:21:01, 11.57s/it, acc=32.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 25/3557 [05:24<11:21:01, 11.57s/it, acc=34.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 26/3557 [05:24<11:04:30, 11.29s/it, acc=34.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 26/3557 [05:30<11:04:30, 11.29s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 27/3557 [05:30<9:29:00,  9.67s/it, acc=33.3%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 27/3557 [05:55<9:29:00,  9.67s/it, acc=32.1%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 28/3557 [05:55<13:52:53, 14.16s/it, acc=32.1%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 28/3557 [05:57<13:52:53, 14.16s/it, acc=31.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 29/3557 [05:57<10:31:38, 10.74s/it, acc=31.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 29/3557 [06:01<10:31:38, 10.74s/it, acc=30.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 30/3557 [06:01<8:31:12,  8.70s/it, acc=30.0%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 30/3557 [06:12<8:31:12,  8.70s/it, acc=29.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 31/3557 [06:12<9:02:39,  9.23s/it, acc=29.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 31/3557 [06:17<9:02:39,  9.23s/it, acc=31.2%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 32/3557 [06:17<7:47:50,  7.96s/it, acc=31.2%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 32/3557 [06:31<7:47:50,  7.96s/it, acc=33.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 33/3557 [06:31<9:34:31,  9.78s/it, acc=33.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 33/3557 [06:47<9:34:31,  9.78s/it, acc=32.4%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 34/3557 [06:47<11:21:31, 11.61s/it, acc=32.4%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 34/3557 [06:56<11:21:31, 11.61s/it, acc=34.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 35/3557 [06:56<10:33:49, 10.80s/it, acc=34.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 35/3557 [07:01<10:33:49, 10.80s/it, acc=36.1%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 36/3557 [07:01<8:56:22,  9.14s/it, acc=36.1%, conf=1.00, last=‚úì] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 36/3557 [07:04<8:56:22,  9.14s/it, acc=35.1%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 37/3557 [07:04<7:11:19,  7.35s/it, acc=35.1%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 37/3557 [07:22<7:11:19,  7.35s/it, acc=34.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 38/3557 [07:22<10:24:56, 10.66s/it, acc=34.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 38/3557 [07:26<10:24:56, 10.66s/it, acc=33.3%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 39/3557 [07:26<8:20:24,  8.53s/it, acc=33.3%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 39/3557 [07:48<8:20:24,  8.53s/it, acc=35.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 40/3557 [07:48<12:19:08, 12.61s/it, acc=35.0%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 40/3557 [08:01<12:19:08, 12.61s/it, acc=36.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 41/3557 [08:01<12:19:29, 12.62s/it, acc=36.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 41/3557 [08:06<12:19:29, 12.62s/it, acc=35.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 42/3557 [08:06<9:59:34, 10.23s/it, acc=35.7%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 42/3557 [08:10<9:59:34, 10.23s/it, acc=37.2%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 43/3557 [08:10<8:22:50,  8.59s/it, acc=37.2%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 43/3557 [08:18<8:22:50,  8.59s/it, acc=38.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 44/3557 [08:18<8:05:24,  8.29s/it, acc=38.6%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|          | 44/3557 [08:43<8:05:24,  8.29s/it, acc=37.8%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 45/3557 [08:43<12:54:56, 13.24s/it, acc=37.8%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 45/3557 [08:51<12:54:56, 13.24s/it, acc=37.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 46/3557 [08:51<11:31:14, 11.81s/it, acc=37.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 46/3557 [09:02<11:31:14, 11.81s/it, acc=38.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 47/3557 [09:02<11:08:03, 11.42s/it, acc=38.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 47/3557 [09:08<11:08:03, 11.42s/it, acc=37.5%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 48/3557 [09:08<9:47:10, 10.04s/it, acc=37.5%, conf=1.00, last=‚úó] Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 48/3557 [09:27<9:47:10, 10.04s/it, acc=36.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 49/3557 [09:27<12:19:09, 12.64s/it, acc=36.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 49/3557 [09:38<12:19:09, 12.64s/it, acc=36.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 50/3557 [09:38<11:52:45, 12.19s/it, acc=36.0%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 50/3557 [09:53<11:52:45, 12.19s/it, acc=37.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 51/3557 [09:53<12:31:13, 12.86s/it, acc=37.3%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 51/3557 [10:17<12:31:13, 12.86s/it, acc=36.5%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 52/3557 [10:17<15:59:12, 16.42s/it, acc=36.5%, conf=0.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 52/3557 [10:23<15:59:12, 16.42s/it, acc=35.8%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 53/3557 [10:23<12:43:32, 13.07s/it, acc=35.8%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   1%|‚ñè         | 53/3557 [10:28<12:43:32, 13.07s/it, acc=35.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 54/3557 [10:28<10:21:09, 10.64s/it, acc=35.2%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 54/3557 [10:34<10:21:09, 10.64s/it, acc=36.4%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 55/3557 [10:34<9:10:58,  9.44s/it, acc=36.4%, conf=1.00, last=‚úì] Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 55/3557 [10:58<9:10:58,  9.44s/it, acc=35.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 56/3557 [10:58<13:19:31, 13.70s/it, acc=35.7%, conf=1.00, last=‚úó]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 56/3557 [11:02<13:19:31, 13.70s/it, acc=36.8%, conf=1.00, last=‚úì]Gemma-3-12B-vLLM_CoT-Voting_n1:   2%|‚ñè         | 57/3557 [11:02<10:24:04, 10.70s/it, acc=36.8%, con