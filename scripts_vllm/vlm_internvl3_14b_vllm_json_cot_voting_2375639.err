Job 2375639: Running on node(s) serv-3315
Job 2375639: Started at 2025-12-10 10:46:46+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375639&from=1765360006000
srun: jobinfo: version v1.0.0
Job 2375639: Running on node(s) serv-3315
Job 2375639: Started at 2025-12-10 10:46:47+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2375639&from=1765360007000
Job 2375639: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2375639: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 21.1 seconds
Error: [Errno 13] Permission denied: '/netscratch/root'
/usr/bin/bash: line 12: /netscratch/root/.venv/vllm_internvl/bin/activate: No such file or directory
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
transformer-engine 1.1.0+cf6fc89 requires flash-attn!=2.0.9,!=2.1.0,<=2.3.3,>=1.0.6, which is not installed.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.
matplotlib 3.8.2 requires numpy<2,>=1.21, but you have numpy 2.2.6 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
cudf 23.10.0 requires numba<0.58,>=0.57, but you have numba 0.61.2 which is incompatible.
cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
dask-cudf 23.10.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.
opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= "3.9", but you have numpy 1.26.4 which is incompatible.
spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.20.0 which is incompatible.
torch-tensorrt 2.2.0a0 requires torch<2.3.0,>=2.1.0.dev, but you have torch 2.9.0 which is incompatible.
torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.9.0 which is incompatible.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
[2025-12-10 10:51:18] INFO run_internvl3_14b_vllm_cot_voting.py:281: üöÄ Starte InternVL3-14B-CoT-Voting_n1: 3557 Aufgaben offen
[2025-12-10 10:51:18] INFO run_internvl3_14b_vllm_cot_voting.py:140: üèóÔ∏è Lade InternVL3-14B-CoT-Voting_n1 mit vLLM
[2025-12-10 10:51:18] INFO run_internvl3_14b_vllm_cot_voting.py:141: ‚öôÔ∏è Config: CoT + Voting (k=1, T=0.0)
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[2025-12-10 10:51:19] INFO configuration_internvl_chat.py:69: vision_select_layer: -1
[2025-12-10 10:51:19] INFO configuration_internvl_chat.py:70: ps_version: v2
[2025-12-10 10:51:19] INFO configuration_internvl_chat.py:71: min_dynamic_patch: 1
[2025-12-10 10:51:19] INFO configuration_internvl_chat.py:72: max_dynamic_patch: 12
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:17<01:47, 17.94s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:34<01:26, 17.21s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:48<01:01, 15.47s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  57% Completed | 4/7 [01:05<00:48, 16.31s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  71% Completed | 5/7 [01:11<00:25, 12.59s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards:  86% Completed | 6/7 [01:29<00:14, 14.47s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [01:48<00:00, 15.84s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Loading safetensors checkpoint shards: 100% Completed | 7/7 [01:48<00:00, 15.49s/it]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m 
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|‚ñè         | 1/51 [00:00<00:07,  6.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|‚ñç         | 2/51 [00:00<00:06,  7.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|‚ñå         | 3/51 [00:00<00:06,  7.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|‚ñä         | 4/51 [00:00<00:05,  8.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|‚ñà‚ñâ        | 10/51 [00:01<00:03, 10.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03, 10.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03, 11.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03, 11.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:02, 12.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:01<00:02, 12.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02, 12.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02, 13.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:01, 13.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:01, 13.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:02<00:01, 14.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:02<00:01, 14.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:02<00:01, 14.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:02<00:01, 14.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:00, 14.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:03<00:00, 14.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:03<00:00, 14.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:03<00:00, 14.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:03<00:00, 15.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:03<00:00, 15.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:03<00:00, 15.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:03<00:00, 12.91it/s]
[0;36m(EngineCore_DP0 pid=4164318)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|‚ñå         | 2/35 [00:00<00:02, 11.76it/s]Capturing CUDA graphs (decode, FULL):  11%|‚ñà‚ñè        | 4/35 [00:00<00:02, 12.75it/s]Capturing CUDA graphs (decode, FULL):  17%|‚ñà‚ñã        | 6/35 [00:00<00:02, 12.97it/s]Capturing CUDA graphs (decode, FULL):  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 13.59it/s]Capturing CUDA graphs (decode, FULL):  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 14.02it/s]Capturing CUDA graphs (decode, FULL):  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:00<00:01, 14.12it/s]Capturing CUDA graphs (decode, FULL):  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:01<00:01, 14.47it/s]Capturing CUDA graphs (decode, FULL):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:01, 14.85it/s]Capturing CUDA graphs (decode, FULL):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:01, 15.23it/s]Capturing CUDA graphs (decode, FULL):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:01<00:00, 15.46it/s]Capturing CUDA graphs (decode, FULL):  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 15.68it/s]Capturing CUDA graphs (decode, FULL):  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 15.93it/s]Capturing CUDA graphs (decode, FULL):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 15.37it/s]Capturing CUDA graphs (decode, FULL):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 15.94it/s]Capturing CUDA graphs (decode, FULL):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:02<00:00, 16.37it/s]Capturing CUDA graphs (decode, FULL):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:02<00:00, 16.79it/s]Capturing CUDA graphs (decode, FULL):  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:02<00:00, 16.78it/s]Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 15.30it/s]
