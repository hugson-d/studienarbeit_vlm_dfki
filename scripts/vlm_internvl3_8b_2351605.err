Job 2351605: Running on node(s) serv-3336
Job 2351605: Started at 2025-12-01 23:11:52+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2351605&from=1764627112000
srun: jobinfo: version v1.0.0
Job 2351605: Running on node(s) serv-3336
Job 2351605: Started at 2025-12-01 23:11:55+0100
Monitor this job here: http://monitoring.pegasus.kl.dfki.de/d/slurm-job-details/job-details?var-jobid=2351605&from=1764627115000
Job 2351605: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh
Job 2351605: creating container for /enroot/nvcr.io_nvidia_pytorch_23.12-py3.sqsh took 19.5 seconds
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /usr/local/lib/python3.10/dist-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
2025-12-01 23:15:09,455 - INFO - üìÇ Dataset geladen: 3557 Aufgaben
2025-12-01 23:15:09,456 - INFO - üöÄ Starte InternVL3-8B: 3557/3557 Tasks ausstehend
2025-12-01 23:15:09,457 - INFO - üèóÔ∏è Lade InternVL3-8B (8B)
2025-12-01 23:15:09,458 - INFO -    HuggingFace ID: OpenGVLab/InternVL3-8B
2025-12-01 23:15:09,458 - INFO -    4-Bit Quantisierung: False
2025-12-01 23:15:09,459 - INFO -    üì• Lade Processor...
A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL3-8B:
- configuration_intern_vit.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL3-8B:
- configuration_internvl_chat.py
- configuration_intern_vit.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
2025-12-01 23:15:12,127 - INFO - vision_select_layer: -1
2025-12-01 23:15:12,128 - INFO - ps_version: v2
2025-12-01 23:15:12,129 - INFO - min_dynamic_patch: 1
2025-12-01 23:15:12,129 - INFO - max_dynamic_patch: 12
2025-12-01 23:15:12,131 - INFO - vision_config is None. Initializing the InternVisionConfig with default values.
2025-12-01 23:15:12,132 - INFO - llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).
2025-12-01 23:15:12,132 - INFO - vision_select_layer: -1
2025-12-01 23:15:12,133 - INFO - ps_version: v1
2025-12-01 23:15:12,134 - INFO - min_dynamic_patch: 1
2025-12-01 23:15:12,135 - INFO - max_dynamic_patch: 6
2025-12-01 23:15:16,049 - INFO -    üì• Lade Modell...
/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
2025-12-01 23:15:16,357 - INFO - vision_select_layer: -1
2025-12-01 23:15:16,358 - INFO - ps_version: v2
2025-12-01 23:15:16,359 - INFO - min_dynamic_patch: 1
2025-12-01 23:15:16,360 - INFO - max_dynamic_patch: 12
2025-12-01 23:15:16,361 - INFO - vision_config is None. Initializing the InternVisionConfig with default values.
2025-12-01 23:15:16,362 - INFO - llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).
2025-12-01 23:15:16,363 - INFO - vision_select_layer: -1
2025-12-01 23:15:16,363 - INFO - ps_version: v1
2025-12-01 23:15:16,364 - INFO - min_dynamic_patch: 1
2025-12-01 23:15:16,365 - INFO - max_dynamic_patch: 6
Traceback (most recent call last):
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/models/run_internvl3_8b.py", line 488, in <module>
    run_benchmark()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/models/run_internvl3_8b.py", line 376, in run_benchmark
    evaluator = VLMEvaluator()
  File "/netscratch/dhug/studienarbeit_vlm_dfki/src/eval/models/run_internvl3_8b.py", line 235, in __init__
    self.model = AutoModelForVision2Seq.from_pretrained(MODEL_HF_ID, **load_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py", line 2289, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py", line 607, in from_pretrained
    raise ValueError(
ValueError: Unrecognized configuration class <class 'transformers_modules.OpenGVLab.InternVL3_hyphen_8B.853e3a797a661694b1b8ece0cb72dc2b23e3dac9.configuration_internvl_chat.InternVLChatConfig'> for this kind of AutoModel: AutoModelForVision2Seq.
Model type should be one of BlipConfig, Blip2Config, ChameleonConfig, GitConfig, Idefics2Config, Idefics3Config, InstructBlipConfig, InstructBlipVideoConfig, Kosmos2Config, Kosmos2_5Config, LlavaConfig, LlavaNextConfig, LlavaNextVideoConfig, LlavaOnevisionConfig, Mistral3Config, MllamaConfig, Ovis2Config, PaliGemmaConfig, Pix2StructConfig, Qwen2_5_VLConfig, Qwen2VLConfig, Qwen3VLConfig, Qwen3VLMoeConfig, VideoLlavaConfig, VipLlavaConfig, VisionEncoderDecoderConfig.
srun: error: serv-3336: task 0: Exited with exit code 1
